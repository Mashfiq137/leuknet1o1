{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os \n",
    "import time\n",
    "#import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "from keras.utils import np_utils\n",
    "#from imgaug import augmenters as iaa    \n",
    "import itertools\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "#from classification_models.keras import Classifiers\n",
    "# GPU test\n",
    "from tensorflow.python.client import device_lib\n",
    "np.random.seed(42)\n",
    "from keras.models import load_model\n",
    "# Print version\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.regularizers import l2\n",
    "import os, sys\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random \n",
    "import shutil \n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation,Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import sys\n",
    "import cv2\n",
    "import efficientnet.keras as efn\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10661, 256, 256, 3), (10661, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.load(\"x_train_299.npy\")\n",
    "y_train = np.load(\"y_train_299.npy\")\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1867, 256, 256, 3), (1867, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.load(\"x_val_299.npy\")\n",
    "y_val = np.load(\"y_val_299.npy\")\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "Tensorflow Version 1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"Tensorflow Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15848189787584595512,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1410301542\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1752533899871045378\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get compute specs\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\rizvee\\anaconda3\\envs\\leukemia\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-8-193183065d88>:28: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 128, 128, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 128, 128, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 128, 128, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 128, 128, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 128, 128, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 128, 128, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 128, 128, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 128, 128, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 128, 128, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 128, 128, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 128, 128, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 128, 128, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 64, 64, 96)   864         block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 64, 64, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 64, 64, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 64, 64, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 64, 64, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 64, 64, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 64, 64, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 64, 64, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 64, 64, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 64, 64, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 64, 64, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 64, 64, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 64, 64, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 64, 64, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 64, 64, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 64, 64, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 64, 64, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 64, 64, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 64, 64, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 64, 64, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 32, 32, 144)  3600        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 32, 32, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 32, 32, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 32, 32, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 32, 32, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 32, 32, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 32, 32, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 32, 32, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 32, 32, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 32, 32, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 32, 32, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 32, 32, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 32, 32, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 32, 32, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 32, 32, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 32, 32, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 32, 32, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 32, 32, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 32, 32, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 32, 32, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 16, 16, 240)  2160        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 16, 16, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 16, 16, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 16, 16, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 16, 16, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 16, 16, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 16, 16, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 16, 16, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 16, 16, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 16, 16, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 16, 16, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 16, 16, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 16, 16, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 16, 16, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 16, 16, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 16, 16, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 16, 16, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 16, 16, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 16, 16, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 16, 16, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 16, 16, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 16, 16, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 16, 16, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 16, 16, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 16, 16, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 16, 16, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 16, 16, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 16, 16, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 16, 16, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 16, 16, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 16, 16, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 16, 16, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 16, 16, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 16, 16, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 16, 16, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 16, 16, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 16, 16, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 16, 16, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 16, 16, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 16, 16, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 16, 16, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 16, 16, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 16, 16, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 16, 16, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 16, 16, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 16, 16, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 16, 16, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 16, 16, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 16, 16, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 16, 16, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 16, 16, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 16, 16, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 16, 16, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 16, 16, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 16, 16, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 16, 16, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 16, 16, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 16, 16, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 16, 16, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 16, 16, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 16, 16, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 16, 16, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 8, 8, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 8, 8, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 8, 8, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 8, 8, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 8, 8, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 8, 8, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 8, 8, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 8, 8, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 8, 8, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 8, 8, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 8, 8, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 8, 8, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 8, 8, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 8, 8, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 8, 8, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 8, 8, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 8, 8, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 8, 8, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 8, 8, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 8, 8, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 8, 8, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 8, 8, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 8, 8, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 8, 8, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 8, 8, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 8, 8, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 8, 8, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 8, 8, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 8, 8, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 8, 8, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 8, 8, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 8, 8, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 8, 8, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 8, 8, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 8, 8, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 8, 8, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 8, 8, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 8, 8, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 8, 8, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 8, 8, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 8, 8, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 8, 8, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 8, 8, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 8, 8, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 8, 8, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 8, 8, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 8, 8, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 8, 8, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 8, 8, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 8, 8, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2562        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 4,052,126\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 42,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def effnet():\n",
    "    # build model\n",
    "    base_model = efn.EfficientNetB0(input_shape=(256,256,3), weights='imagenet', include_top=False)\n",
    "    \n",
    "    # add GAP layer and 2-ways softmax\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    output = keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[base_model.input], outputs=[output])\n",
    "    model.compile(optimizer='SGD', loss=f1_loss, metrics=['accuracy'] )\n",
    "    return model\n",
    "\n",
    "\n",
    "model=None\n",
    "model=effnet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('effnetb0.h5', monitor='val_acc', save_best_only=True, mode='max'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, verbose=1, patience=5, mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 0.68211 , 1: 0.3178}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10661 samples, validate on 1867 samples\n",
      "Epoch 1/50\n",
      "10661/10661 [==============================] - 495s 46ms/step - loss: 0.1624 - acc: 0.7648 - val_loss: 0.5674 - val_acc: 0.6867\n",
      "Epoch 2/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.1226 - acc: 0.7999 - val_loss: 0.5639 - val_acc: 0.7225\n",
      "Epoch 3/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.1093 - acc: 0.8157 - val_loss: 0.5718 - val_acc: 0.7124\n",
      "Epoch 4/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0972 - acc: 0.8343 - val_loss: 0.5626 - val_acc: 0.7333\n",
      "Epoch 5/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0903 - acc: 0.8510 - val_loss: 0.5713 - val_acc: 0.7531\n",
      "Epoch 6/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0838 - acc: 0.8594 - val_loss: 0.5736 - val_acc: 0.7424\n",
      "Epoch 7/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0768 - acc: 0.8752 - val_loss: 0.5705 - val_acc: 0.7450\n",
      "Epoch 8/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0762 - acc: 0.8770 - val_loss: 0.5709 - val_acc: 0.7531\n",
      "Epoch 9/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0686 - acc: 0.8845 - val_loss: 0.5700 - val_acc: 0.7756\n",
      "Epoch 10/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0675 - acc: 0.8900 - val_loss: 0.5586 - val_acc: 0.7927\n",
      "Epoch 11/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0652 - acc: 0.8939 - val_loss: 0.5601 - val_acc: 0.7852\n",
      "Epoch 12/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0625 - acc: 0.8980 - val_loss: 0.5582 - val_acc: 0.7868\n",
      "Epoch 13/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0584 - acc: 0.9066 - val_loss: 0.5564 - val_acc: 0.7933\n",
      "Epoch 14/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0576 - acc: 0.9089 - val_loss: 0.5686 - val_acc: 0.7611\n",
      "Epoch 15/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0553 - acc: 0.9125 - val_loss: 0.5654 - val_acc: 0.7766\n",
      "Epoch 16/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0540 - acc: 0.9146 - val_loss: 0.5682 - val_acc: 0.7590\n",
      "Epoch 17/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0521 - acc: 0.9176 - val_loss: 0.5553 - val_acc: 0.8093\n",
      "Epoch 18/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.0520 - acc: 0.9172 - val_loss: 0.5992 - val_acc: 0.6722\n",
      "Epoch 19/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.0514 - acc: 0.9203 - val_loss: 0.5776 - val_acc: 0.7338\n",
      "Epoch 20/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0503 - acc: 0.9223 - val_loss: 0.5649 - val_acc: 0.7884\n",
      "Epoch 21/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0480 - acc: 0.9268 - val_loss: 0.5706 - val_acc: 0.7531\n",
      "Epoch 22/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0467 - acc: 0.9292 - val_loss: 0.5554 - val_acc: 0.8120\n",
      "Epoch 23/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.0428 - acc: 0.9344 - val_loss: 0.5636 - val_acc: 0.7831\n",
      "Epoch 24/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0466 - acc: 0.9275 - val_loss: 0.6174 - val_acc: 0.6288\n",
      "Epoch 25/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0439 - acc: 0.9357 - val_loss: 0.5537 - val_acc: 0.8190\n",
      "Epoch 26/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0437 - acc: 0.9341 - val_loss: 0.5963 - val_acc: 0.6861\n",
      "Epoch 27/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0415 - acc: 0.9364 - val_loss: 0.6141 - val_acc: 0.6326\n",
      "Epoch 28/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0386 - acc: 0.9431 - val_loss: 0.5637 - val_acc: 0.7799\n",
      "Epoch 29/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0401 - acc: 0.9407 - val_loss: 0.5844 - val_acc: 0.7290\n",
      "Epoch 30/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0379 - acc: 0.9466 - val_loss: 0.5691 - val_acc: 0.7616\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 31/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0371 - acc: 0.9487 - val_loss: 0.5556 - val_acc: 0.8082\n",
      "Epoch 32/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0360 - acc: 0.9514 - val_loss: 0.5546 - val_acc: 0.8141\n",
      "Epoch 33/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0361 - acc: 0.9497 - val_loss: 0.5540 - val_acc: 0.8157\n",
      "Epoch 34/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0341 - acc: 0.9534 - val_loss: 0.5538 - val_acc: 0.8147\n",
      "Epoch 35/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.0329 - acc: 0.9554 - val_loss: 0.5533 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 36/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.0338 - acc: 0.9547 - val_loss: 0.5521 - val_acc: 0.8222\n",
      "Epoch 37/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0329 - acc: 0.9545 - val_loss: 0.5527 - val_acc: 0.8184\n",
      "Epoch 38/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0356 - acc: 0.9519 - val_loss: 0.5532 - val_acc: 0.8157\n",
      "Epoch 39/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0350 - acc: 0.9525 - val_loss: 0.5526 - val_acc: 0.8190\n",
      "Epoch 40/50\n",
      "10661/10661 [==============================] - 392s 37ms/step - loss: 0.0354 - acc: 0.9542 - val_loss: 0.5533 - val_acc: 0.8179\n",
      "Epoch 41/50\n",
      "10661/10661 [==============================] - 391s 37ms/step - loss: 0.0357 - acc: 0.9523 - val_loss: 0.5532 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 42/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0344 - acc: 0.9529 - val_loss: 0.5537 - val_acc: 0.8141\n",
      "Epoch 43/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0348 - acc: 0.9527 - val_loss: 0.5524 - val_acc: 0.8195\n",
      "Epoch 44/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0322 - acc: 0.9557 - val_loss: 0.5519 - val_acc: 0.8227\n",
      "Epoch 45/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0343 - acc: 0.9527 - val_loss: 0.5523 - val_acc: 0.8211\n",
      "Epoch 46/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0337 - acc: 0.9552 - val_loss: 0.5534 - val_acc: 0.8168\n",
      "Epoch 47/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0339 - acc: 0.9539 - val_loss: 0.5526 - val_acc: 0.8190\n",
      "Epoch 48/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0320 - acc: 0.9542 - val_loss: 0.5527 - val_acc: 0.8254\n",
      "Epoch 49/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0336 - acc: 0.9526 - val_loss: 0.5529 - val_acc: 0.8168\n",
      "Epoch 50/50\n",
      "10661/10661 [==============================] - 390s 37ms/step - loss: 0.0333 - acc: 0.9536 - val_loss: 0.5538 - val_acc: 0.8157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28345104198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, validation_data = (x_val,y_val), batch_size = 8, epochs=50 ,callbacks=callbacks, verbose=1, shuffle=True, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
