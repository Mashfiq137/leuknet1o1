{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'C:\\Users\\DIPTO\\Desktop\\train'\n",
    "VAL_DIRECTORY = r'C:\\Users\\DIPTO\\Desktop\\val'\n",
    "\n",
    "CATEGORIES = ['all', 'hem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, bounding):\n",
    "    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "    end = tuple(map(operator.add, start, bounding))\n",
    "    slices = tuple(map(slice, start, end))\n",
    "    return img[slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path)\n",
    "        crop_arr = crop_center(arr, (210,210))\n",
    "        if 1 <= i+1 <= 140:                      # total 140 image\n",
    "            ax = plt.subplot(13, 11, i+1)\n",
    "        plt.imshow(crop_arr)\n",
    "        i += 1\n",
    "        data.append([crop_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(VAL_DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path)\n",
    "        crop_arr = crop_center(arr, (210,210))\n",
    "        if 1 <= i+1 <= 70:                     # total image 70\n",
    "            ax = plt.subplot(10, 7, i+1)\n",
    "        plt.imshow(crop_arr)\n",
    "        i += 1\n",
    "        val_data.append([crop_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(val_data)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for features, label in val_data:\n",
    "    x_val.append(features)\n",
    "    y_val.append(label)\n",
    "\n",
    "    \n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_val   = x_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(210,210,3),\n",
    "    pooling=None,\n",
    "    classes=1,\n",
    "    classifier_activation=\"sigmoid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n",
    "#sgd_opt = SGD(lr=1e-06, momentum=0.0, decay=0.0, nesterov=False)\n",
    "rmsp_opt = RMSprop(lr=1e-4, decay=0.9)\n",
    "# eve_opt = Eve(lr=1e-4, decay=1E-4, beta_1=0.9, beta_2=0.999, beta_3=0.999, small_k=0.1, big_K=10, epsilon=1e-08)\n",
    "\n",
    "model.compile(optimizer= adam_opt,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('baseline_vgg.h5', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, verbose=1, patience=5, mode='max')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data = (x_val,y_val), verbose = 1, batch_size=28, epochs = 1, shuffle = True, callbacks = callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
